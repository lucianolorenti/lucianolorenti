{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Remaining useful life predictions is a complex beast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d217fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import everything we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3fa64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from crull.transformers.IonMillEtchTool import IonMillEtchTool_expanding_transformer, IonMillEtchTool_raw_transformer\n",
    "import rul_pm.datasets.PHMDataset2018 as IonMillEtchToolDataset\n",
    "from rul_pm.datasets.PHMDataset2018 import PHMDataset2018 as PHMDataset2018Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from temporis.iterators.utils import true_values\n",
    "from crull.graphics.graphics import (histogram_categorical,\n",
    "                                     add_vertical_lines_annotations)\n",
    "import seaborn as sbn\n",
    "from tqdm.auto import tqdm\n",
    "from tensorflow.keras import Model, Input\n",
    "import tensorflow_addons as tfa\n",
    "from tcn import TCN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Conv1D, Dense, \n",
    "                                     Flatten, Dropout, LSTM, GlobalAveragePooling1D,\n",
    "                                     Activation,\n",
    "                                     LSTM, BatchNormalization, GRU, LeakyReLU,\n",
    "                                     Permute,\n",
    "                                    Reshape)\n",
    "from tensorflow_addons.layers import WeightNormalization\n",
    "from temporis.models.keras import tf_regression_dataset\n",
    "import tensorflow \n",
    "sbn.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443e2cf",
   "metadata": {},
   "source": [
    "# Dataset description and pre-processing\n",
    "Before beggining is would be to understand what is the problem we want to solver.\n",
    "\n",
    "RUL-PM already pre-process all this for us and prepare a dataset ready to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6675a89",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49791dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PHMDataset2018Dataset(\n",
    "    failure_types=IonMillEtchToolDataset.FailureType.FlowCoolPressureDroppedBelowLimit,\n",
    "    tools='03_M02')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e811e1f6",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e02f008",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36cd11b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TransformerStep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36366/258912467.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mScalingPerRecipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransformerStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mstandard_scaler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_partial_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TransformerStep' is not defined"
     ]
    }
   ],
   "source": [
    "class ScalingPerRecipe(TransformerStep):\n",
    "    def __init__(self, * , standard_scaler:bool=False):\n",
    "        super().__init__(prefer_partial_fit=False)\n",
    "        self.means = {}\n",
    "        self.std = {}\n",
    "        self.max = {}\n",
    "        self.min = {}\n",
    "        self.standard = standard_scaler\n",
    "        self.recipes = set()\n",
    "\n",
    "\n",
    "    def fit(self, X:pd.DataFrame):\n",
    "        \n",
    "        \n",
    "        for g, data in X.groupby('recipe'):\n",
    "            if self.standard:\n",
    "                self.means[g] = data.mean()\n",
    "                self.std[g] = data.std()\n",
    "            else:\n",
    "                self.max[g] = data.max()\n",
    "                self.min[g] = data.min()\n",
    "            self.recipes.add(g)\n",
    "        return self \n",
    "\n",
    "    def transform(self, X:pd.DataFrame):\n",
    "        X_new = X.copy().drop(columns='recipe')\n",
    "        for g, data in X.groupby('recipe'):\n",
    "            index = data.index\n",
    "            if g not in self.recipes:\n",
    "                continue\n",
    "            \n",
    "            if self.standard:\n",
    "                X_new.loc[index, :] =(X_new.loc[index, :]-self.means[g])/self.std[g]\n",
    "            else:\n",
    "                X_new.loc[index, :] =(X_new.loc[index, :]-self.min[g])/(self.max[g]-self.min[g])\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2827be1",
   "metadata": {},
   "source": [
    "## Raw transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4426121",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_raw = ByNameFeatureSelector(features=features + ['recipe'])\n",
    "pipe_raw = RecipeEffectRemoval()(pipe_raw)\n",
    "pipe_raw = MeanImputer()(pipe_raw)\n",
    "\n",
    "stage_cat = OneHotCategorical(feature='FIXTURESHUTTERPOSITION')\n",
    "\n",
    "pipe_raw = Concatenate()([pipe_raw, stage_cat])\n",
    "\n",
    "\n",
    "y_pipe = ByNameFeatureSelector(features=[\"RUL\"])\n",
    "\n",
    "\n",
    "raw_transformer = Transformer(\n",
    "    transformerX=pipe_raw,\n",
    "    transformerY=y_pipe\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6315ef",
   "metadata": {},
   "source": [
    "## Extracing features transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11245849",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_raw = ByNameFeatureSelector(features=features + ['recipe'])\n",
    "pipe_raw = RecipeEffectRemoval()(pipe_raw)\n",
    "pipe_raw = MeanImputer()(pipe_raw)\n",
    "\n",
    "expanding = ByNameFeatureSelector(features=features + ['recipe'])\n",
    "expanding = RecipeEffectRemoval()(expanding)\n",
    "expanding = ExpandingStatistics(to_compute=['rms', 'std', 'mean', 'std_atan'])(expanding)\n",
    "\n",
    "stage_cat = OneHotCategorical(feature='FIXTURESHUTTERPOSITION')\n",
    "\n",
    "pipe_raw = Concatenate()([pipe_raw, stage_cat, expanding])\n",
    "\n",
    "\n",
    "y_pipe = ByNameFeatureSelector(features=[\"RUL\"])\n",
    "\n",
    "\n",
    "raw_transformer = Transformer(\n",
    "    transformerX=pipe_raw,\n",
    "    transformerY=y_pipe\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729d91c4",
   "metadata": {},
   "source": [
    "# Sliding window iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e96a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 500\n",
    "train_iterator = WindowedDatasetIterator(\n",
    "    transformed_train_dataset,\n",
    "    window,\n",
    "    step=1,\n",
    "    \n",
    "    start_index=RelativeToEnd(3000),\n",
    "    shuffler=AllShuffled(),\n",
    "\n",
    ")\n",
    "\n",
    "train_not_shuffled_iterator = WindowedDatasetIterator(\n",
    "    transformed_train_dataset,\n",
    "    window,\n",
    "    step=5,\n",
    "    \n",
    "    start_index=RelativeToEnd(3000),\n",
    ")\n",
    "\n",
    "val_iterator = WindowedDatasetIterator(\n",
    "    transformed_val_dataset,\n",
    "    window,\n",
    "    step=15,\n",
    "    \n",
    "    shuffler=NotShuffled(),\n",
    "    start_index=RelativeToEnd(3000),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d958344",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c09fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "train_set, val_set = train_test_split(dataset, train_size=0.8, shuffle=True)\n",
    "\n",
    "transformed_train_dataset = train_set.map(transformer)\n",
    "transformed_val_dataset = val_set.map(transformer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
